{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Assignment 1\n",
    "Due by 8th May, 2024 at 23:59 CEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Basics\n",
    "\n",
    "We want to create a 2 layer NN, which means we want to calculate  $y = W_2 * ReLU(W_1 * x + b_1) + b_2$\n",
    "\n",
    "Complete the TODOs below to create such a NN.\n",
    "\n",
    "Since you will be needing to compute the gradients w.r.t. all parameters, you may look into online resources for help. Please cite or link any online recources you do use.\n",
    "\n",
    "You are allowed to change any existing parts, however the code has to remain easy to understand and well documented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def relu(x):\n",
    "    \"\"\"\n",
    "    ReLU activation function\n",
    "    \n",
    "    Parameters:\n",
    "        x (np.ndarray): numpy array with shape (m, n) where m is the number of dimensions and n is the number of points\n",
    "        \n",
    "    Returns:\n",
    "        x' (np.ndarray): return value of the pointwise ReLU application\n",
    "    \"\"\"\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "def relu_grad(x):\n",
    "    # TODO: Write a function given a numpy array that calculates the gradient of the ReLU function w.r.t. `x`\n",
    "    # TODO: Also write the derivation of the gradient in the PDF file In the implementation you may simply use the final derivation.\n",
    "    # Hint: The function should return a numpy array of the same dimension that `x` has, but only containing 0 or 1\n",
    "    arr = np.zeros(x.shape)\n",
    "    return np.greater(x, arr).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumPyNeuralNet:\n",
    "    \n",
    "    def __init__(self, dim_in, dim_hidden, dim_out):\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_out = dim_out\n",
    "        \n",
    "        # TODO: Randomly initialize the weight matrices W_1, W_2 and biases b_1, b_2\n",
    "        # Hint: use np.random.randn() and make sure to correctly set the dimensions \n",
    "\n",
    "        # Scale random sample with 0.01 according to lecture\n",
    "        self.W_1 = 0.01 * np.random.randn(self.dim_in, self.dim_hidden)\n",
    "        self.b_1 = 0.01 * np.random.randn(self.dim_hidden)\n",
    "        self.W_2 = 0.01 * np.random.randn(self.dim_hidden, self.dim_out)\n",
    "        self.b_2 = 0.01 * np.random.randn(self.dim_out)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Calculates the output of the neural network for the given x.\n",
    "        \n",
    "        Parameters:\n",
    "            x (np.ndarray): input value numpy array\n",
    "        \n",
    "        Returns:\n",
    "            y (np.ndarray): predicted output for `x`\n",
    "        \"\"\"\n",
    "        # TODO: Calculate output self.out\n",
    "        # Safe intermediate results as cache for later backpropagation\n",
    "        self.h_1 = np.dot(x, self.W_1) + self.b_1\n",
    "        self.h_1_act = relu(self.h_1)\n",
    "        self.out = np.dot(self.h_1_act, self.W_2) + self.b_2\n",
    "        return self.out\n",
    "    \n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        \"\"\"\n",
    "        Calculates the Mean-Squared Error and returns the gradients w.r.t. to the parameters.\n",
    "        \n",
    "        Parameters:\n",
    "            x (np.ndarray): input value numpy array with shape (self.dim_in, n)\n",
    "            y (np.ndarray): ground truth value numpy array with shape (self.dim_out, n)\n",
    "            \n",
    "        Returns:\n",
    "            loss (float): Mean-Squared-Error between predicted value on input points and ground truth value\n",
    "            W_1_grad (np.ndarray): gradient w.r.t W_1   \n",
    "            W_2_grad (np.ndarray): gradient w.r.t W_2  \n",
    "            b_1_grad (np.ndarray): gradient w.r.t b_1   \n",
    "            b_2_grad (np.ndarray): gradient w.r.t b_2   \n",
    "        \"\"\"\n",
    "        # TODO: Calculate the loss (Mean-Squared-Error)\n",
    "        # Hint: use np.square() and np.mean()\n",
    "\n",
    "        y_pred = self.predict(x)\n",
    "        loss = np.mean(np.square(y_pred - y))\n",
    "        \n",
    "        # TODO: Calculate all gradients w.r.t to the parameters\n",
    "        # Hint: You need to calculate the gradients for each of the parameters by hand\n",
    "        # TODO: Also write the derivation of the gradient in the PDF file. In the implementation you may simply use the final derivation.\n",
    "\n",
    "        loss_derived = 2 * (self.out - y) / len(y)\n",
    "        \n",
    "        h_1_grad = np.dot(loss_derived, self.W_2.T) * relu_grad(self.h_1)\n",
    "        \n",
    "        W_2_grad = np.dot(self.h_1_act.T, loss_derived)\n",
    "        b_2_grad = np.sum(loss_derived, axis=0)\n",
    "        W_1_grad = np.dot(x.T, h_1_grad)\n",
    "        b_1_grad = np.sum(h_1_grad, axis=0)\n",
    "\n",
    "        return loss, W_1_grad, W_2_grad, b_1_grad, b_2_grad\n",
    "         \n",
    "    def train(self, x, y, lr=0.001, epochs=1000):\n",
    "        \"\"\"\n",
    "        Train the neural network with gradient descent.\n",
    "        \n",
    "        Parameters:\n",
    "            x (np.ndarray): input values\n",
    "            y (np.ndarray): ground truth values\n",
    "            lr (float): learning rate, default: 0.001\n",
    "            epochs (int): number of epochs to train, default: 1000\n",
    "            \n",
    "        Returns:\n",
    "            loss (float): Return the loss achieved after all epochs\n",
    "        \"\"\"\n",
    "        # TODO: Keep track of the loss\n",
    "        loss_history = []\n",
    "        n = len(x)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # shuffle dataset\n",
    "            idx = np.arange(n)\n",
    "            np.random.shuffle(idx)\n",
    "            x_shuffled = x[idx]\n",
    "            y_shuffled = y[idx]\n",
    "\n",
    "            for i in range(n):\n",
    "                dp_x = x_shuffled[i]\n",
    "                dp_y = y_shuffled[i]\n",
    "                \n",
    "                loss, W_1_grad, W_2_grad, b_1_grad, b_2_grad = self.loss(dp_x.reshape(1,-1), dp_y.reshape(1,-1))\n",
    "                \n",
    "                self.W_1 -= lr * W_1_grad\n",
    "                self.W_2 -= lr * W_2_grad\n",
    "                self.b_1 -= lr * b_1_grad\n",
    "                self.b_2 -= lr * b_2_grad\n",
    "\n",
    "                loss_history.append(loss)\n",
    "            \n",
    "            \n",
    "            # print mean loss of dataset every 10% of epochs\n",
    "            e = int(epochs / 10)\n",
    "            if epoch % e == 0:\n",
    "                print(f'Epoch {epoch}, Loss: {np.mean(loss_history[-n:])}')\n",
    "\n",
    "        \n",
    "        # TODO: Plot the loss history and return the loss achieved after the final epoch\n",
    "        # Plot the loss history after every epoch. Returned is the mean loss of the last epoch.\n",
    "        loss_per_epoch = [np.mean(loss_history[i*n:(i+1)*n]) for i in range(epochs)]\n",
    "        plt.plot(loss_per_epoch)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss')\n",
    "        plt.show()\n",
    "\n",
    "        return loss_per_epoch[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.3048135152827944\n",
      "Epoch 100, Loss: 0.004766474955605456\n",
      "Epoch 200, Loss: 0.001929123905124359\n",
      "Epoch 300, Loss: 0.0011586061105498446\n",
      "Epoch 400, Loss: 0.0008842943399885283\n",
      "Epoch 500, Loss: 0.0007160753823985639\n",
      "Epoch 600, Loss: 0.0005888245134945728\n",
      "Epoch 700, Loss: 0.000526121102732088\n",
      "Epoch 800, Loss: 0.0005047205437658141\n",
      "Epoch 900, Loss: 0.0004532285108616859\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after final epoch: 0.00043452530197944737\n",
      "Example predictions of model: \n",
      "x:0.4 y:[[0.1717219]]\n",
      "x:0.5 y:[[0.24908155]]\n",
      "x:0.7 y:[[0.49592807]]\n",
      "\n",
      " if these examples are predicted badly, the model might only perform well on training set\n"
     ]
    }
   ],
   "source": [
    "# We test the model created above on the simple function y = x^2\n",
    "\n",
    "model = NumPyNeuralNet(1, 30, 1)\n",
    "\n",
    "# Create a randomly distributed array of 1000 values between 0 and 1\n",
    "x_train = 1 * np.random.randn(1000, 1)\n",
    "# Create ground truth by calculating x*x\n",
    "y_train = x_train * x_train\n",
    "\n",
    "# Train for default epochs\n",
    "loss = model.train(x_train, y_train)\n",
    "print(\"loss after final epoch: \" + str(loss))\n",
    "example_1 = 0.4\n",
    "example_2 = 0.5\n",
    "example_3 = 0.7\n",
    "print(\"Example predictions of model: \" + \"\\n\" + \"x:\" + str(example_1) + \" y:\" + str(model.predict(example_1)) + \"\\n\"\n",
    "      + \"x:\" + str(example_2) + \" y:\" + str(model.predict(example_2)) + \"\\n\" + \"x:\" + str(example_3) + \" y:\" + str(model.predict(example_3)))\n",
    "print(\"\\n if these examples are predicted badly, the model might only perform well on training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "### Intrinsic evaluation of embeddings\n",
    "Word similarity task is often used as an intrinsic evaluation criteria. In the dataset file you will find a list of word pairs with their similarity scores as judged by humans. The task would be to judge how well are the word vectors aligned to human judgement. We will use word2vec embedding vectors trained on the google news corpus. (Ignore the pairs where at least one the words is absent in the corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional libraries from students\n",
    "from gensim.models import Word2Vec\n",
    "import torch as torch\n",
    "import numpy as np\n",
    "import csv\n",
    "from torchmetrics import SpearmanCorrCoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = []      \n",
    "    isFirstLine = True\n",
    "    for line in open('wordsim353_dataset.csv'):\n",
    "        if isFirstLine:\n",
    "            isFirstLine = False\n",
    "            continue\n",
    "        indices = [i for i, x in enumerate(line) if x == \",\"]\n",
    "        w1 = line[:indices[0]]\n",
    "        w2 = line[indices[0]+1:indices[1]]\n",
    "        mean = float(line[indices[1]+1:].rstrip())\n",
    "        # print(f\"w1: {w1}, w2: {w2}, mean: {mean}\")\n",
    "        data.append((w1, w2, mean))\n",
    "    return data\n",
    "\n",
    "# data = load_data()\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which takes as input two words and computes the cosine similarity between them.\n",
    "You do not need to implement the cosine similarity calculation from scratch. Feel free to use any Python library.\n",
    "Remeber to ignore any pairs where at least one word is absent in the corpus. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(word1, word2):\n",
    "    # TODO: check missing words\n",
    "    cos = nn.CosineSimilarity(dim=0)\n",
    "    output = cos(word1, word2)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the similarity between all the word pairs in the list and sort them based on the similarity scores. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(w):\n",
    "    return torch.from_numpy(wv[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_scores(data):\n",
    "    # data = load_data()\n",
    "    scores = []\n",
    "    \n",
    "    # # scores = torch.tensor([])\n",
    "\n",
    "    for w1, w2, mean in data:\n",
    "        # empty words\n",
    "        if not w1 or not w2:\n",
    "            continue\n",
    "\n",
    "        # word2vec as tensors for cos_score\n",
    "        w1_vec = torch.from_numpy(wv[w1])\n",
    "        w2_vec = torch.from_numpy(wv[w2])\n",
    "        cos_score = similarity(w1_vec, w2_vec)\n",
    "        \n",
    "        scores.append([w1, w2, cos_score.item()])\n",
    "        # # scores = torch.cat((prev_word, word, cos_score.reshape(1)))\n",
    "    return sorted(scores, key=lambda entry: entry[2])\n",
    "# sim_scores = compute_similarity_scores(load_data())\n",
    "# print(len(sim_scores))\n",
    "# print(sim_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the word pairs in the list based on the human judgement scores. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_judgement_scores(data):\n",
    "    # data = load_data()\n",
    "    return sorted(data, key=lambda entry: entry[2])\n",
    "# human_scores = human_judgement_scores(loaddata())\n",
    "# print(human_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute spearman rank correlation between the two ranked lists obtained in the previous two steps.\n",
    "You do not need to implement the spearman rank correlation calculation from scratch. Feel free to use any Python library. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('love', 'sex', 6.77), ('tiger', 'cat', 7.35), ('tiger', 'tiger', 10.0), ('book', 'paper', 7.46), ('computer', 'keyboard', 7.62), ('computer', 'internet', 7.58), ('plane', 'car', 5.77), ('train', 'car', 6.31), ('telephone', 'communication', 7.5), ('television', 'radio', 6.77), ('media', 'radio', 7.42), ('drug', 'abuse', 6.85), ('bread', 'butter', 6.19), ('cucumber', 'potato', 5.92), ('doctor', 'nurse', 7.0), ('professor', 'doctor', 6.62), ('student', 'professor', 6.81), ('smart', 'student', 4.62), ('smart', 'stupid', 5.81), ('company', 'stock', 7.08), ('stock', 'market', 8.08), ('stock', 'phone', 1.62), ('stock', 'CD', 1.31), ('stock', 'jaguar', 0.92), ('stock', 'egg', 1.81), ('fertility', 'egg', 6.69), ('stock', 'live', 3.73), ('stock', 'life', 0.92), ('book', 'library', 7.46), ('bank', 'money', 8.12), ('wood', 'forest', 7.73), ('money', 'cash', 9.15), ('professor', 'cucumber', 0.31), ('king', 'cabbage', 0.23), ('king', 'queen', 8.58), ('king', 'rook', 5.92), ('bishop', 'rabbi', 6.69), ('Jerusalem', 'Israel', 8.46), ('Jerusalem', 'Palestinian', 7.65), ('holy', 'sex', 1.62), ('fuck', 'sex', 9.44), ('Maradona', 'football', 8.62), ('football', 'soccer', 9.03), ('football', 'basketball', 6.81), ('football', 'tennis', 6.63), ('tennis', 'racket', 7.56), ('Arafat', 'peace', 6.73), ('Arafat', 'terror', 7.65), ('Arafat', 'Jackson', 2.5), ('law', 'lawyer', 8.38), ('movie', 'star', 7.38), ('movie', 'popcorn', 6.19), ('movie', 'critic', 6.73), ('movie', 'theater', 7.92), ('physics', 'proton', 8.12), ('physics', 'chemistry', 7.35), ('space', 'chemistry', 4.88), ('alcohol', 'chemistry', 5.54), ('vodka', 'gin', 8.46), ('vodka', 'brandy', 8.13), ('drink', 'car', 3.04), ('drink', 'ear', 1.31), ('drink', 'mouth', 5.96), ('drink', 'eat', 6.87), ('baby', 'mother', 7.85), ('drink', 'mother', 2.65), ('car', 'automobile', 8.94), ('gem', 'jewel', 8.96), ('journey', 'voyage', 9.29), ('boy', 'lad', 8.83), ('coast', 'shore', 9.1), ('asylum', 'madhouse', 8.87), ('magician', 'wizard', 9.02), ('midday', 'noon', 9.29), ('furnace', 'stove', 8.79), ('food', 'fruit', 7.52), ('bird', 'cock', 7.1), ('bird', 'crane', 7.38), ('tool', 'implement', 6.46), ('brother', 'monk', 6.27), ('crane', 'implement', 2.69), ('lad', 'brother', 4.46), ('journey', 'car', 5.85), ('monk', 'oracle', 5.0), ('cemetery', 'woodland', 2.08), ('food', 'rooster', 4.42), ('coast', 'hill', 4.38), ('forest', 'graveyard', 1.85), ('shore', 'woodland', 3.08), ('monk', 'slave', 0.92), ('coast', 'forest', 3.15), ('lad', 'wizard', 0.92), ('chord', 'smile', 0.54), ('glass', 'magician', 2.08), ('noon', 'string', 0.54), ('rooster', 'voyage', 0.62), ('money', 'dollar', 8.42), ('money', 'cash', 9.08), ('money', 'currency', 9.04), ('money', 'wealth', 8.27), ('money', 'property', 7.57), ('money', 'possession', 7.29), ('money', 'bank', 8.5), ('money', 'deposit', 7.73), ('money', 'withdrawal', 6.88), ('money', 'laundering', 5.65), ('money', 'operation', 3.31), ('tiger', 'jaguar', 8.0), ('tiger', 'feline', 8.0), ('tiger', 'carnivore', 7.08), ('tiger', 'mammal', 6.85), ('tiger', 'animal', 7.0), ('tiger', 'organism', 4.77), ('tiger', 'fauna', 5.62), ('tiger', 'zoo', 5.87), ('psychology', 'psychiatry', 8.08), ('psychology', 'anxiety', 7.0), ('psychology', 'fear', 6.85), ('psychology', 'depression', 7.42), ('psychology', 'clinic', 6.58), ('psychology', 'doctor', 6.42), ('psychology', 'Freud', 8.21), ('psychology', 'mind', 7.69), ('psychology', 'health', 7.23), ('psychology', 'science', 6.71), ('psychology', 'discipline', 5.58), ('psychology', 'cognition', 7.48), ('planet', 'star', 8.45), ('planet', 'constellation', 8.06), ('planet', 'moon', 8.08), ('planet', 'sun', 8.02), ('planet', 'galaxy', 8.11), ('planet', 'space', 7.92), ('planet', 'astronomer', 7.94), ('precedent', 'example', 5.85), ('precedent', 'information', 3.85), ('precedent', 'cognition', 2.81), ('precedent', 'law', 6.65), ('precedent', 'collection', 2.5), ('precedent', 'group', 1.77), ('precedent', 'antecedent', 6.04), ('cup', 'coffee', 6.58), ('cup', 'tableware', 6.85), ('cup', 'article', 2.4), ('cup', 'artifact', 2.92), ('cup', 'object', 3.69), ('cup', 'entity', 2.15), ('cup', 'drink', 7.25), ('cup', 'food', 5.0), ('cup', 'substance', 1.92), ('cup', 'liquid', 5.9), ('jaguar', 'cat', 7.42), ('jaguar', 'car', 7.27), ('energy', 'secretary', 1.81), ('secretary', 'senate', 5.06), ('energy', 'laboratory', 5.09), ('computer', 'laboratory', 6.78), ('weapon', 'secret', 6.06), ('FBI', 'fingerprint', 6.94), ('FBI', 'investigation', 8.31), ('investigation', 'effort', 4.59), ('Mars', 'water', 2.94), ('Mars', 'scientist', 5.63), ('news', 'report', 8.16), ('canyon', 'landscape', 7.53), ('image', 'surface', 4.56), ('discovery', 'space', 6.34), ('water', 'seepage', 6.56), ('sign', 'recess', 2.38), ('Wednesday', 'news', 2.22), ('mile', 'kilometer', 8.66), ('computer', 'news', 4.47), ('territory', 'surface', 5.34), ('atmosphere', 'landscape', 3.69), ('president', 'medal', 3.0), ('war', 'troops', 8.13), ('record', 'number', 6.31), ('skin', 'eye', 6.22), ('Japanese', 'American', 6.5), ('theater', 'history', 3.91), ('volunteer', 'motto', 2.56), ('prejudice', 'recognition', 3.0), ('decoration', 'valor', 5.63), ('century', 'year', 7.59), ('century', 'nation', 3.16), ('delay', 'racism', 1.19), ('delay', 'news', 3.31), ('minister', 'party', 6.63), ('peace', 'plan', 4.75), ('minority', 'peace', 3.69), ('attempt', 'peace', 4.25), ('government', 'crisis', 6.56), ('deployment', 'departure', 4.25), ('deployment', 'withdrawal', 5.88), ('energy', 'crisis', 5.94), ('announcement', 'news', 7.56), ('announcement', 'effort', 2.75), ('stroke', 'hospital', 7.03), ('disability', 'death', 5.47), ('victim', 'emergency', 6.47), ('treatment', 'recovery', 7.91), ('journal', 'association', 4.97), ('doctor', 'personnel', 5.0), ('doctor', 'liability', 5.19), ('liability', 'insurance', 7.03), ('school', 'center', 3.44), ('reason', 'hypertension', 2.31), ('reason', 'criterion', 5.91), ('hundred', 'percent', 7.38), ('Harvard', 'Yale', 8.13), ('hospital', 'infrastructure', 4.63), ('death', 'row', 5.25), ('death', 'inmate', 5.03), ('lawyer', 'evidence', 6.69), ('life', 'death', 7.88), ('life', 'term', 4.5), ('word', 'similarity', 4.75), ('board', 'recommendation', 4.47), ('governor', 'interview', 3.25), ('OPEC', 'country', 5.63), ('peace', 'atmosphere', 3.69), ('peace', 'insurance', 2.94), ('territory', 'kilometer', 5.28), ('travel', 'activity', 5.0), ('competition', 'price', 6.44), ('consumer', 'confidence', 4.13), ('consumer', 'energy', 4.75), ('problem', 'airport', 2.38), ('car', 'flight', 4.94), ('credit', 'card', 8.06), ('credit', 'information', 5.31), ('hotel', 'reservation', 8.03), ('grocery', 'money', 5.94), ('registration', 'arrangement', 6.0), ('arrangement', 'accommodation', 5.41), ('month', 'hotel', 1.81), ('type', 'kind', 8.97), ('arrival', 'hotel', 6.0), ('bed', 'closet', 6.72), ('closet', 'clothes', 8.0), ('situation', 'conclusion', 4.81), ('situation', 'isolation', 3.88), ('impartiality', 'interest', 5.16), ('direction', 'combination', 2.25), ('street', 'place', 6.44), ('street', 'avenue', 8.88), ('street', 'block', 6.88), ('street', 'children', 4.94), ('listing', 'proximity', 2.56), ('listing', 'category', 6.38), ('cell', 'phone', 7.81), ('production', 'hike', 1.75), ('benchmark', 'index', 4.25), ('media', 'trading', 3.88), ('media', 'gain', 2.88), ('dividend', 'payment', 7.63), ('dividend', 'calculation', 6.48), ('calculation', 'computation', 8.44), ('currency', 'market', 7.5), ('OPEC', 'oil', 8.59), ('oil', 'stock', 6.34), ('announcement', 'production', 3.38), ('announcement', 'warning', 6.0), ('profit', 'warning', 3.88), ('profit', 'loss', 7.63), ('dollar', 'yen', 7.78), ('dollar', 'buck', 9.22), ('dollar', 'profit', 7.38), ('dollar', 'loss', 6.09), ('computer', 'software', 8.5), ('network', 'hardware', 8.31), ('phone', 'equipment', 7.13), ('equipment', 'maker', 5.91), ('luxury', 'car', 6.47), ('five', 'month', 3.38), ('report', 'gain', 3.63), ('investor', 'earning', 7.13), ('liquid', 'water', 7.89), ('baseball', 'season', 5.97), ('game', 'victory', 7.03), ('game', 'team', 7.69), ('marathon', 'sprint', 7.47), ('game', 'series', 6.19), ('game', 'defeat', 6.97), ('seven', 'series', 3.56), ('seafood', 'sea', 7.47), ('seafood', 'food', 8.34), ('seafood', 'lobster', 8.7), ('lobster', 'food', 7.81), ('lobster', 'wine', 5.7), ('food', 'preparation', 6.22), ('video', 'archive', 6.34), ('start', 'year', 4.06), ('start', 'match', 4.47), ('game', 'round', 5.97), ('boxing', 'round', 7.61), ('championship', 'tournament', 8.36), ('fighting', 'defeating', 7.41), ('line', 'insurance', 2.69), ('day', 'summer', 3.94), ('summer', 'drought', 7.16), ('summer', 'nature', 5.63), ('day', 'dawn', 7.53), ('nature', 'environment', 8.31), ('environment', 'ecology', 8.81), ('nature', 'man', 6.25), ('man', 'woman', 8.3), ('man', 'governor', 5.25), ('murder', 'manslaughter', 8.53), ('soap', 'opera', 7.94), ('opera', 'performance', 6.88), ('life', 'lesson', 5.94), ('focus', 'life', 4.06), ('production', 'crew', 6.25), ('television', 'film', 7.72), ('lover', 'quarrel', 6.19), ('viewer', 'serial', 2.97), ('possibility', 'girl', 1.94), ('population', 'development', 3.75), ('morality', 'importance', 3.31), ('morality', 'marriage', 3.69), ('Mexico', 'Brazil', 7.44), ('gender', 'equality', 6.41), ('change', 'attitude', 5.44), ('family', 'planning', 6.25), ('opera', 'industry', 2.63), ('sugar', 'approach', 0.88), ('practice', 'institution', 3.19), ('ministry', 'culture', 4.69), ('problem', 'challenge', 6.75), ('size', 'prominence', 5.31), ('country', 'citizen', 7.31), ('planet', 'people', 5.75), ('development', 'issue', 3.97), ('experience', 'music', 3.47), ('music', 'project', 3.63), ('glass', 'metal', 5.56), ('aluminum', 'metal', 7.83), ('chance', 'credibility', 3.88), ('exhibit', 'memorabilia', 5.31), ('concert', 'virtuoso', 6.81), ('rock', 'jazz', 7.59), ('museum', 'theater', 7.19), ('observation', 'architecture', 4.38), ('space', 'world', 6.53), ('preservation', 'world', 6.19), ('admission', 'ticket', 7.69), ('shower', 'thunderstorm', 6.31), ('shower', 'flood', 6.03), ('weather', 'forecast', 8.34), ('disaster', 'area', 6.25), ('governor', 'office', 6.34), ('architecture', 'century', 3.78)]\n",
      "['tiger' 'tiger' '10.0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_spearman():\n",
    "    data = load_data()\n",
    "    print(data)\n",
    "\n",
    "    sim_score = np.array(compute_similarity_scores(data))\n",
    "    human_score = np.array(human_judgement_scores(data))\n",
    "\n",
    "    # use third column of dataset (mean/cos_similarity)\n",
    "    preds = torch.from_numpy(sim_score[:, 2].astype(float))\n",
    "    target = torch.from_numpy(human_score[:, 2].astype(float))\n",
    "\n",
    "    spearman = SpearmanCorrCoef()\n",
    "    return spearman(preds, target)\n",
    "compute_spearman()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding based clasifier\n",
    "We will design a simple sentiment classifier based on the pre-trained word embeddings (google news).\n",
    "\n",
    "Each data point is a movie review and the sentiment could be either positive (1) or negative (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1821"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('sentiment_test_X.p', 'rb') as fs:\n",
    "    test_X = pickle.load(fs)\n",
    "\n",
    "len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If',\n",
       " 'you',\n",
       " 'sometimes',\n",
       " 'like',\n",
       " 'to',\n",
       " 'go',\n",
       " 'to',\n",
       " 'the',\n",
       " 'movies',\n",
       " 'to',\n",
       " 'have',\n",
       " 'fun',\n",
       " ',',\n",
       " 'Wasabi',\n",
       " 'is',\n",
       " 'a',\n",
       " 'good',\n",
       " 'place',\n",
       " 'to',\n",
       " 'start',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.91015625e-02 -1.20117188e-01 -9.42382812e-02  2.69531250e-01\n",
      "  2.57568359e-02 -3.68652344e-02  9.42382812e-02  2.41210938e-01\n",
      " -1.47460938e-01 -8.05664062e-02  2.33398438e-01 -1.42578125e-01\n",
      "  1.21582031e-01 -1.56250000e-01 -1.23901367e-02  1.92382812e-01\n",
      "  1.08398438e-01  1.11328125e-01  4.05273438e-02 -2.34375000e-01\n",
      "  1.85546875e-01  1.97265625e-01  1.35742188e-01  3.10546875e-01\n",
      " -1.49414062e-01 -4.67300415e-05  9.03320312e-03 -3.51562500e-02\n",
      "  6.78710938e-02 -2.33398438e-01 -3.39843750e-01  5.22460938e-02\n",
      "  3.51562500e-01  1.25000000e-01  3.95507812e-02 -1.98242188e-01\n",
      "  1.40625000e-01 -1.86523438e-01  2.94921875e-01  3.20312500e-01\n",
      "  8.54492188e-02 -3.22265625e-01  1.14746094e-01  1.01562500e-01\n",
      " -1.54296875e-01 -4.68750000e-02 -2.83203125e-02  1.24511719e-01\n",
      "  1.91406250e-01  2.31445312e-01 -1.07421875e-01  1.69921875e-01\n",
      "  8.64257812e-02  8.93554688e-02  9.17968750e-02 -4.66308594e-02\n",
      "  9.96093750e-02 -3.16406250e-01  6.68945312e-02 -1.08398438e-01\n",
      " -1.30859375e-01 -3.56445312e-02 -1.26953125e-01  2.35595703e-02\n",
      " -3.80859375e-02  1.54296875e-01 -2.31445312e-01 -4.82177734e-03\n",
      " -1.22070312e-01  8.74023438e-02  2.85156250e-01  7.27539062e-02\n",
      "  1.46484375e-01 -1.31835938e-01  6.59179688e-02 -2.02941895e-03\n",
      "  2.11181641e-02 -1.37695312e-01  5.73730469e-02  1.67968750e-01\n",
      " -7.76367188e-02 -1.51367188e-01 -1.04003906e-01  8.36181641e-03\n",
      " -2.51953125e-01 -1.81640625e-01 -2.14843750e-01  3.75000000e-01\n",
      "  2.50000000e-01  5.66406250e-02  5.76171875e-02 -7.71484375e-02\n",
      " -5.71289062e-02 -9.76562500e-02 -1.75781250e-01 -2.76184082e-03\n",
      "  1.13281250e-01  3.45703125e-01 -3.29589844e-02 -6.64062500e-02\n",
      " -1.51367188e-01  3.57421875e-01 -1.31835938e-01  2.20703125e-01\n",
      "  1.08398438e-01  3.22265625e-02  2.47070312e-01 -1.46484375e-01\n",
      "  1.30462646e-03 -1.55273438e-01 -4.61425781e-02  1.35742188e-01\n",
      "  1.79443359e-02  4.46777344e-02  2.75390625e-01 -1.74804688e-01\n",
      "  1.99218750e-01 -1.16210938e-01 -8.66699219e-03 -2.53906250e-01\n",
      " -1.94335938e-01  4.66308594e-02  1.80664062e-01  1.36718750e-01\n",
      " -3.97949219e-02 -1.40380859e-03 -4.00390625e-02  7.95898438e-02\n",
      " -2.83203125e-01  5.93261719e-02 -3.96484375e-01 -2.94921875e-01\n",
      " -8.78906250e-02  1.69921875e-01 -1.50390625e-01  1.04003906e-01\n",
      "  2.17773438e-01  8.39843750e-02 -3.08837891e-02  1.80664062e-01\n",
      "  1.63085938e-01 -4.63867188e-02  1.20605469e-01 -2.57812500e-01\n",
      " -1.43554688e-01  6.59179688e-02  1.84631348e-03  6.44531250e-02\n",
      "  2.80761719e-02 -2.71484375e-01  1.14746094e-01  1.55273438e-01\n",
      " -2.51953125e-01  1.06445312e-01 -9.42382812e-02 -1.54296875e-01\n",
      "  2.15820312e-01 -1.84570312e-01 -3.86718750e-01 -2.31445312e-01\n",
      "  3.46679688e-02  3.24218750e-01 -1.12304688e-02  5.00000000e-01\n",
      "  2.07031250e-01 -2.09960938e-01  8.25195312e-02  6.93359375e-02\n",
      "  1.55273438e-01  7.08007812e-02 -1.83593750e-01  8.60595703e-03\n",
      " -3.75976562e-02  1.66992188e-01 -4.10156250e-02  1.66015625e-01\n",
      " -5.68847656e-02 -1.14257812e-01 -1.60156250e-01  7.76367188e-02\n",
      " -8.93554688e-02 -9.32617188e-02 -1.25732422e-02  6.22558594e-02\n",
      " -1.50390625e-01 -2.33154297e-02  3.80859375e-02 -1.96289062e-01\n",
      "  9.91210938e-02 -4.16015625e-01 -9.61914062e-02  1.30859375e-01\n",
      " -6.88476562e-02  1.27929688e-01  7.56835938e-03  6.93359375e-02\n",
      " -1.72119141e-02  5.32226562e-02 -1.97265625e-01 -2.85156250e-01\n",
      "  8.78906250e-02 -2.95410156e-02 -2.91015625e-01 -1.71875000e-01\n",
      "  8.42285156e-03 -7.17773438e-02 -8.93554688e-02 -7.03125000e-02\n",
      " -3.22265625e-01  1.91406250e-01  1.31835938e-01  3.06640625e-01\n",
      " -1.23046875e-01  1.70898438e-01  2.22656250e-01 -1.05957031e-01\n",
      " -1.53198242e-02  3.83300781e-02  9.15527344e-03  7.93457031e-03\n",
      " -6.68945312e-02  2.34375000e-01  3.06396484e-02 -1.18652344e-01\n",
      " -7.47070312e-02  6.54296875e-02  1.06201172e-02 -6.44531250e-02\n",
      " -2.79541016e-02 -1.20117188e-01 -1.31835938e-01  3.22265625e-01\n",
      "  2.09960938e-02  6.20117188e-02  2.53906250e-01 -5.83496094e-02\n",
      " -6.00585938e-02 -1.96533203e-02  1.67968750e-01  9.71679688e-02\n",
      "  6.34765625e-02  1.11328125e-01 -3.16406250e-01 -2.55859375e-01\n",
      " -1.85546875e-01  3.43750000e-01  2.92968750e-02  5.06591797e-03\n",
      " -3.66210938e-02 -4.23828125e-01 -7.17773438e-02  1.92382812e-01\n",
      "  1.98242188e-01  2.43164062e-01  3.97949219e-02 -4.49218750e-02\n",
      " -9.03320312e-02 -2.36328125e-01 -1.21093750e-01 -1.35742188e-01\n",
      " -1.01074219e-01 -8.30078125e-02 -7.61718750e-02  2.49023438e-02\n",
      " -2.83203125e-01  1.58203125e-01  1.25000000e-01 -1.50390625e-01\n",
      " -1.88476562e-01  1.14746094e-01 -4.12597656e-02  2.98828125e-01\n",
      "  2.94921875e-01  9.52148438e-02  2.67578125e-01 -2.96875000e-01\n",
      " -2.17285156e-02 -6.59179688e-02 -1.51367188e-01  4.61425781e-02\n",
      "  1.68945312e-01 -7.78198242e-04 -1.94335938e-01 -4.24804688e-02\n",
      "  1.37695312e-01 -2.00195312e-01 -1.32812500e-01  7.56835938e-02\n",
      " -3.24707031e-02  1.25976562e-01 -1.89208984e-02  3.94531250e-01\n",
      " -2.19726562e-01 -1.89208984e-02 -2.00195312e-01 -3.71093750e-02\n",
      "  2.43164062e-01 -1.35742188e-01 -3.22265625e-02 -7.27539062e-02]\n"
     ]
    }
   ],
   "source": [
    "print(wv['fun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1821"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('sentiment_test_y.p', 'rb') as fs:\n",
    "    test_y = pickle.load(fs)\n",
    "    \n",
    "len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentiment_train_X.p', 'rb') as fs:\n",
    "    train_X = pickle.load(fs)\n",
    "with open('sentiment_train_y.p', 'rb') as fs:\n",
    "    train_y = pickle.load(fs)\n",
    "with open('sentiment_val_X.p', 'rb') as fs:\n",
    "    val_X = pickle.load(fs)\n",
    "with open('sentiment_val_y.p', 'rb') as fs:\n",
    "    val_y = pickle.load(fs)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a review, compute its embedding by averaging over the embedding of its constituent words. Define a function which given a review as a list of words, generates its embeddings by averaging over the constituent word embeddings. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(review):\n",
    "    # print([wv[word] for word in review if word in wv])\n",
    "    print([word for word in review if word in wv])\n",
    "    print(len(wv['fun']))\n",
    "    return np.mean([wv[word] for word in review if word in wv], axis=0)\n",
    "\n",
    "# [word1, word2, word3]\n",
    "# [wv1, wv2,]\n",
    "\n",
    "# generate_embedding(test_X[0])\n",
    "# generate_embedding(train_X[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a feed-forward network class with pytorch. (Hyperparamter choice such as number of layers, hidden size is left to you) (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_1_size, hidden_2_size, output_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_1_size = hidden_1_size\n",
    "        self.hidden_2_size = hidden_2_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.fc_1 = nn.Linear(self.input_size, self.hidden_1_size)\n",
    "        self.fc_2 = nn.Linear(self.hidden_1_size, self.hidden_2_size)\n",
    "        self.fc_3 = nn.Linear(self.hidden_2_size, self.output_size)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        torch.nn.init.xavier_uniform_(self.fc_1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc_2.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc_3.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_1 = self.relu(self.fc_1(x))\n",
    "        h_2 = self.relu(self.fc_2(h_1))\n",
    "        return self.fc_3(h_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dataset class for efficiently enumerating over the dataset. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sent_data(Dataset):\n",
    "    def __init__(self, data_points, class_labels):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.data = data_points\n",
    "        self.labels = class_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        d = torch.Tensor(generate_embedding(self.data[index]))\n",
    "        l = torch.Tensor([self.labels[index]])\n",
    "        return d,l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a train function to train model. At the end of each epoch compute the validation accuracy and save the model with the best validation accuracy. (12 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "# Adopt your code to incorporate mini-batch training\n",
    "# Use cross-entropy as your loss function\n",
    "def train(model, train_data, val_data, batch_size, epochs=5, learning_rate=0.001):\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for _ in tqdm(range(epochs)): # the models are trained over multiple epochs..\n",
    "        train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        for d, l in train_dataloader:\n",
    "            out = model(d)\n",
    "            print(out)\n",
    "            print(l)\n",
    "            l = l.squeeze(1) # converts the tensor of shape [50 x 1] to [50]\n",
    "            # loss = criterion(out, l)\n",
    "            loss =  nn.CrossEntropyLoss(out, l)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the trained model on the test set and report the test accuracy. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Its', 'appeal', 'will', 'probably', 'limited', 'LDS', 'Church', 'members', 'undemanding', 'armchair', 'tourists']\n",
      "300\n",
      "['Such', 'master', 'screenwriting', 'comes', 'courtesy', 'John', 'Pogue', 'the', 'Yale', 'grad', 'who', 'previously', 'gave', 'us', 'The', 'Skulls', 'last', 'year', 'Rollerball']\n",
      "300\n",
      "['enough', 'for', 'yet', 'not', 'as', 'hilariously', 'raunchy', 'as', 'South', 'Park', 'this', 'strangely', 'schizo', 'cartoon', 'seems', 'suited', 'neither', 'kids', 'or', 'adults']\n",
      "300\n",
      "['Narc', 'is', 'all', 'menace', 'atmosphere']\n",
      "300\n",
      "['Certain', 'be', 'distasteful', 'children', 'adults', 'alike', 'Eight', 'Crazy', 'Nights', 'is', 'total', 'misfire']\n",
      "300\n",
      "tensor([[-0.0515],\n",
      "        [-0.0712],\n",
      "        [-0.0405],\n",
      "        [-0.0620],\n",
      "        [-0.0180]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m      5\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[75], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_data, val_data, batch_size, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     14\u001b[0m l \u001b[38;5;241m=\u001b[39m l\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# converts the tensor of shape [50 x 1] to [50]\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# loss = criterion(out, l)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m loss \u001b[38;5;241m=\u001b[39m  \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\domri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1180\u001b[0m, in \u001b[0;36mCrossEntropyLoss.__init__\u001b[1;34m(self, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, size_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_index: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m   1179\u001b[0m              reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, label_smoothing: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1180\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index \u001b[38;5;241m=\u001b[39m ignore_index\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing \u001b[38;5;241m=\u001b[39m label_smoothing\n",
      "File \u001b[1;32mc:\\Users\\domri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:30\u001b[0m, in \u001b[0;36m_WeightedLoss.__init__\u001b[1;34m(self, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, size_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m, weight)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight: Optional[Tensor]\n",
      "File \u001b[1;32mc:\\Users\\domri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:23\u001b[0m, in \u001b[0;36m_Loss.__init__\u001b[1;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegacy_get_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction \u001b[38;5;241m=\u001b[39m reduction\n",
      "File \u001b[1;32mc:\\Users\\domri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\_reduction.py:35\u001b[0m, in \u001b[0;36mlegacy_get_string\u001b[1;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     reduce \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mand\u001b[39;00m reduce:\n\u001b[0;32m     36\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m reduce:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "train_data = sent_data(train_X, train_y)\n",
    "test_data = sent_data(test_X, test_y)\n",
    "model = Classifier(300, 2000, 100, 1)\n",
    "batch_size = 50\n",
    "epochs = 5\n",
    "train(model, train_data, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
