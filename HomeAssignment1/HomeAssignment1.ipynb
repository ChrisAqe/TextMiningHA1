{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Assignment 1\n",
    "Due by 8th May, 2024 at 23:59 CEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nChristoph Hlava - 10027820\\nDominik Rittner - 10019667\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Christoph Hlava - 10027820\n",
    "Dominik Rittner - 10019667\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Basics\n",
    "\n",
    "We want to create a 2 layer NN, which means we want to calculate  $y = W_2 * ReLU(W_1 * x + b_1) + b_2$\n",
    "\n",
    "Complete the TODOs below to create such a NN.\n",
    "\n",
    "Since you will be needing to compute the gradients w.r.t. all parameters, you may look into online resources for help. Please cite or link any online recources you do use.\n",
    "\n",
    "You are allowed to change any existing parts, however the code has to remain easy to understand and well documented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def relu(x):\n",
    "    \"\"\"\n",
    "    ReLU activation function\n",
    "    \n",
    "    Parameters:\n",
    "        x (np.ndarray): numpy array with shape (m, n) where m is the number of dimensions and n is the number of points\n",
    "        \n",
    "    Returns:\n",
    "        x' (np.ndarray): return value of the pointwise ReLU application\n",
    "    \"\"\"\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "\n",
    "def relu_grad(x):\n",
    "    # TODO: Write a function given a numpy array that calculates the gradient of the ReLU function w.r.t. `x`\n",
    "    # TODO: Also write the derivation of the gradient in the PDF file In the implementation you may simply use the final derivation.\n",
    "    # Hint: The function should return a numpy array of the same dimension that `x` has, but only containing 0 or 1\n",
    "    arr = np.zeros(x.shape)\n",
    "    return np.greater(x, arr).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumPyNeuralNet:\n",
    "    \n",
    "    def __init__(self, dim_in, dim_hidden, dim_out):\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.dim_out = dim_out\n",
    "        \n",
    "        # TODO: Randomly initialize the weight matrices W_1, W_2 and biases b_1, b_2\n",
    "        # Hint: use np.random.randn() and make sure to correctly set the dimensions \n",
    "\n",
    "        # Scale random sample with 0.01 according to lecture\n",
    "        self.W_1 = 0.01 * np.random.randn(self.dim_in, self.dim_hidden)\n",
    "        self.b_1 = 0.01 * np.random.randn(self.dim_hidden)\n",
    "        self.W_2 = 0.01 * np.random.randn(self.dim_hidden, self.dim_out)\n",
    "        self.b_2 = 0.01 * np.random.randn(self.dim_out)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Calculates the output of the neural network for the given x.\n",
    "        \n",
    "        Parameters:\n",
    "            x (np.ndarray): input value numpy array\n",
    "        \n",
    "        Returns:\n",
    "            y (np.ndarray): predicted output for `x`\n",
    "        \"\"\"\n",
    "        # TODO: Calculate output self.out\n",
    "        # Safe intermediate results as cache for later backpropagation\n",
    "        self.h_1 = np.dot(x, self.W_1) + self.b_1\n",
    "        self.h_1_act = relu(self.h_1)\n",
    "        self.out = np.dot(self.h_1_act, self.W_2) + self.b_2\n",
    "        return self.out\n",
    "    \n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        \"\"\"\n",
    "        Calculates the Mean-Squared Error and returns the gradients w.r.t. to the parameters.\n",
    "        \n",
    "        Parameters:\n",
    "            x (np.ndarray): input value numpy array with shape (self.dim_in, n)\n",
    "            y (np.ndarray): ground truth value numpy array with shape (self.dim_out, n)\n",
    "            \n",
    "        Returns:\n",
    "            loss (float): Mean-Squared-Error between predicted value on input points and ground truth value\n",
    "            W_1_grad (np.ndarray): gradient w.r.t W_1   \n",
    "            W_2_grad (np.ndarray): gradient w.r.t W_2  \n",
    "            b_1_grad (np.ndarray): gradient w.r.t b_1   \n",
    "            b_2_grad (np.ndarray): gradient w.r.t b_2   \n",
    "        \"\"\"\n",
    "        # TODO: Calculate the loss (Mean-Squared-Error)\n",
    "        # Hint: use np.square() and np.mean()\n",
    "\n",
    "        y_pred = self.predict(x)\n",
    "        loss = np.mean(np.square(y_pred - y))\n",
    "        \n",
    "        # TODO: Calculate all gradients w.r.t to the parameters\n",
    "        # Hint: You need to calculate the gradients for each of the parameters by hand\n",
    "        # TODO: Also write the derivation of the gradient in the PDF file. In the implementation you may simply use the final derivation.\n",
    "\n",
    "        loss_derived = 2 * (self.out - y) / len(y)\n",
    "        \n",
    "        h_1_grad = np.dot(loss_derived, self.W_2.T) * relu_grad(self.h_1)\n",
    "        \n",
    "        W_2_grad = np.dot(self.h_1_act.T, loss_derived)\n",
    "        b_2_grad = np.sum(loss_derived, axis=0)\n",
    "        W_1_grad = np.dot(x.T, h_1_grad)\n",
    "        b_1_grad = np.sum(h_1_grad, axis=0)\n",
    "\n",
    "        return loss, W_1_grad, W_2_grad, b_1_grad, b_2_grad\n",
    "         \n",
    "    def train(self, x, y, lr=0.001, epochs=1000):\n",
    "        \"\"\"\n",
    "        Train the neural network with gradient descent.\n",
    "        \n",
    "        Parameters:\n",
    "            x (np.ndarray): input values\n",
    "            y (np.ndarray): ground truth values\n",
    "            lr (float): learning rate, default: 0.001\n",
    "            epochs (int): number of epochs to train, default: 1000\n",
    "            \n",
    "        Returns:\n",
    "            loss (float): Return the loss achieved after all epochs\n",
    "        \"\"\"\n",
    "        # TODO: Keep track of the loss\n",
    "        loss_history = []\n",
    "        n = len(x)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # shuffle dataset\n",
    "            idx = np.arange(n)\n",
    "            np.random.shuffle(idx)\n",
    "            x_shuffled = x[idx]\n",
    "            y_shuffled = y[idx]\n",
    "\n",
    "            for i in range(n):\n",
    "                dp_x = x_shuffled[i]\n",
    "                dp_y = y_shuffled[i]\n",
    "                \n",
    "                loss, W_1_grad, W_2_grad, b_1_grad, b_2_grad = self.loss(dp_x.reshape(1,-1), dp_y.reshape(1,-1))\n",
    "                \n",
    "                self.W_1 -= lr * W_1_grad\n",
    "                self.W_2 -= lr * W_2_grad\n",
    "                self.b_1 -= lr * b_1_grad\n",
    "                self.b_2 -= lr * b_2_grad\n",
    "\n",
    "                loss_history.append(loss)\n",
    "            \n",
    "            \n",
    "            # print mean loss of dataset every 10% of epochs\n",
    "            e = int(epochs / 10)\n",
    "            if epoch % e == 0:\n",
    "                print(f'Epoch {epoch}, Loss: {np.mean(loss_history[-n:])}')\n",
    "\n",
    "        \n",
    "        # TODO: Plot the loss history and return the loss achieved after the final epoch\n",
    "        # Plot the loss history after every epoch. Returned is the mean loss of the last epoch.\n",
    "        loss_per_epoch = [np.mean(loss_history[i*n:(i+1)*n]) for i in range(epochs)]\n",
    "        plt.plot(loss_per_epoch)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Loss')\n",
    "        plt.show()\n",
    "\n",
    "        return loss_per_epoch[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.670844371770125\n",
      "Epoch 100, Loss: 0.006803654680623216\n",
      "Epoch 200, Loss: 0.002605072641078812\n",
      "Epoch 300, Loss: 0.0018921104346553022\n",
      "Epoch 400, Loss: 0.00153990523511671\n",
      "Epoch 500, Loss: 0.0013144465701215133\n",
      "Epoch 600, Loss: 0.0011551067992817343\n",
      "Epoch 700, Loss: 0.0010619083689132277\n",
      "Epoch 800, Loss: 0.0009606911060579919\n",
      "Epoch 900, Loss: 0.0009087522948036884\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after final epoch: 0.0008503233357434286\n",
      "Example predictions of model: \n",
      "x:0.4 y:[[0.14140501]]\n",
      "x:0.5 y:[[0.2628017]]\n",
      "x:0.7 y:[[0.50559507]]\n",
      "\n",
      " if these examples are predicted badly, the model might only perform well on training set\n"
     ]
    }
   ],
   "source": [
    "# We test the model created above on the simple function y = x^2\n",
    "\n",
    "model = NumPyNeuralNet(1, 30, 1)\n",
    "\n",
    "# Create a randomly distributed array of 1000 values between 0 and 1\n",
    "x_train = 1 * np.random.randn(1000, 1)\n",
    "# Create ground truth by calculating x*x\n",
    "y_train = x_train * x_train\n",
    "\n",
    "# Train for default epochs\n",
    "loss = model.train(x_train, y_train)\n",
    "print(\"loss after final epoch: \" + str(loss))\n",
    "example_1 = 0.4\n",
    "example_2 = 0.5\n",
    "example_3 = 0.7\n",
    "print(\"Example predictions of model: \" + \"\\n\" + \"x:\" + str(example_1) + \" y:\" + str(model.predict(example_1)) + \"\\n\"\n",
    "      + \"x:\" + str(example_2) + \" y:\" + str(model.predict(example_2)) + \"\\n\" + \"x:\" + str(example_3) + \" y:\" + str(model.predict(example_3)))\n",
    "print(\"\\n if these examples are predicted badly, the model might only perform well on training set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "### Intrinsic evaluation of embeddings\n",
    "Word similarity task is often used as an intrinsic evaluation criteria. In the dataset file you will find a list of word pairs with their similarity scores as judged by humans. The task would be to judge how well are the word vectors aligned to human judgement. We will use word2vec embedding vectors trained on the google news corpus. (Ignore the pairs where at least one the words is absent in the corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional libraries from students\n",
    "from gensim.models import Word2Vec\n",
    "import torch as torch\n",
    "import numpy as np\n",
    "import csv\n",
    "from torchmetrics import SpearmanCorrCoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = []      \n",
    "    isFirstLine = True\n",
    "    for line in open('wordsim353_dataset.csv'):\n",
    "        if isFirstLine:\n",
    "            isFirstLine = False\n",
    "            continue\n",
    "        indices = [i for i, x in enumerate(line) if x == \",\"]\n",
    "        w1 = line[:indices[0]]\n",
    "        w2 = line[indices[0]+1:indices[1]]\n",
    "        mean = float(line[indices[1]+1:].rstrip())\n",
    "        # print(f\"w1: {w1}, w2: {w2}, mean: {mean}\")\n",
    "        data.append((w1, w2, mean))\n",
    "    return data\n",
    "\n",
    "# data = load_data()\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which takes as input two words and computes the cosine similarity between them.\n",
    "You do not need to implement the cosine similarity calculation from scratch. Feel free to use any Python library.\n",
    "Remeber to ignore any pairs where at least one word is absent in the corpus. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(word1, word2):\n",
    "    # Missing words are taken care of in compute_similarity_scores\n",
    "    cos = nn.CosineSimilarity(dim=0)\n",
    "    output = cos(word1, word2)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the similarity between all the word pairs in the list and sort them based on the similarity scores. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['preservation', 'world', -0.021470628678798676], ['precedent', 'cognition', -0.020569605752825737], ['investor', 'earning', 0.0034081414341926575], ['sugar', 'approach', 0.007720557972788811], ['production', 'hike', 0.018261179327964783], ['music', 'project', 0.02134612202644348], ['noon', 'string', 0.021654512733221054], ['crane', 'implement', 0.023186158388853073], ['delay', 'racism', 0.023803047835826874], ['dollar', 'loss', 0.026566721498966217], ['precedent', 'collection', 0.03283146768808365], ['cup', 'artifact', 0.033699166029691696], ['cup', 'entity', 0.034792210906744], ['stock', 'jaguar', 0.03606690466403961], ['glass', 'magician', 0.0372249037027359], ['discovery', 'space', 0.04125640168786049], ['opera', 'industry', 0.04291349649429321], ['stock', 'live', 0.04447175934910774], ['sign', 'recess', 0.04805115610361099], ['money', 'possession', 0.0531826913356781], ['money', 'withdrawal', 0.05602632462978363], ['professor', 'cucumber', 0.05661814659833908], ['possibility', 'girl', 0.0600377656519413], ['doctor', 'liability', 0.06116040050983429], ['attempt', 'peace', 0.061378709971904755], ['rooster', 'voyage', 0.06275809556245804], ['tiger', 'organism', 0.06294278055429459], ['stock', 'CD', 0.06611791253089905], ['smart', 'student', 0.06630216538906097], ['minority', 'peace', 0.06868557631969452], ['president', 'medal', 0.06946568936109543], ['stock', 'life', 0.07456468045711517], ['reason', 'hypertension', 0.07555150985717773], ['precedent', 'group', 0.07681484520435333], ['space', 'chemistry', 0.0802517756819725], ['announcement', 'production', 0.0806659460067749], ['cup', 'article', 0.08339213579893112], ['line', 'insurance', 0.08391070365905762], ['money', 'operation', 0.0845692902803421], ['planet', 'people', 0.08704743534326553], ['precedent', 'information', 0.08866603672504425], ['alcohol', 'chemistry', 0.08876198530197144], ['development', 'issue', 0.0901077538728714], ['energy', 'secretary', 0.09282554686069489], ['drink', 'ear', 0.09346937388181686], ['cup', 'food', 0.09379564225673676], ['direction', 'combination', 0.09585042297840118], ['word', 'similarity', 0.09658686816692352], ['practice', 'institution', 0.09677622467279434], ['peace', 'insurance', 0.09818778932094574], ['journey', 'car', 0.09849625825881958], ['report', 'gain', 0.09995907545089722], ['holy', 'sex', 0.10070592910051346], ['media', 'gain', 0.10171881318092346], ['problem', 'airport', 0.10208500921726227], ['computer', 'news', 0.1039980947971344], ['stock', 'egg', 0.10417767614126205], ['cup', 'object', 0.10605283081531525], ['listing', 'category', 0.11038407683372498], ['energy', 'laboratory', 0.11277153342962265], ['nature', 'man', 0.11616960912942886], ['prejudice', 'recognition', 0.11657065153121948], ['credit', 'information', 0.11662982404232025], ['shore', 'woodland', 0.116909459233284], ['king', 'cabbage', 0.11813169717788696], ['food', 'rooster', 0.11830645799636841], ['governor', 'interview', 0.11880449205636978], ['peace', 'plan', 0.11900727450847626], ['registration', 'arrangement', 0.11914842575788498], ['OPEC', 'country', 0.1194894015789032], ['psychology', 'clinic', 0.12102102488279343], ['summer', 'nature', 0.12260761111974716], ['stock', 'phone', 0.12326754629611969], ['listing', 'proximity', 0.1236044391989708], ['cup', 'substance', 0.12556418776512146], ['delay', 'news', 0.12586817145347595], ['month', 'hotel', 0.12591953575611115], ['media', 'trading', 0.12612037360668182], ['grocery', 'money', 0.12704519927501678], ['travel', 'activity', 0.12772586941719055], ['image', 'surface', 0.12843585014343262], ['shower', 'flood', 0.1294793337583542], ['space', 'world', 0.1296270787715912], ['theater', 'history', 0.12982811033725739], ['jaguar', 'car', 0.13319405913352966], ['peace', 'atmosphere', 0.13366280496120453], ['size', 'prominence', 0.1337670385837555], ['observation', 'architecture', 0.13629396259784698], ['Mars', 'water', 0.13637156784534454], ['profit', 'warning', 0.13709336519241333], ['phone', 'equipment', 0.13774040341377258], ['energy', 'crisis', 0.13847880065441132], ['territory', 'surface', 0.1395847499370575], ['focus', 'life', 0.14205680787563324], ['school', 'center', 0.14268213510513306], ['architecture', 'century', 0.1430933177471161], ['car', 'flight', 0.14423443377017975], ['disaster', 'area', 0.1452282965183258], ['hospital', 'infrastructure', 0.14553327858448029], ['chord', 'smile', 0.14869235455989838], ['dividend', 'calculation', 0.15065297484397888], ['man', 'governor', 0.15232418477535248], ['street', 'children', 0.15370695292949677], ['territory', 'kilometer', 0.1540842205286026], ['death', 'row', 0.1561247855424881], ['drink', 'mother', 0.15679940581321716], ['arrival', 'hotel', 0.1593550145626068], ['money', 'currency', 0.16010122001171112], ['doctor', 'personnel', 0.16101650893688202], ['coast', 'hill', 0.1611577719449997], ['journal', 'association', 0.16295820474624634], ['summer', 'drought', 0.1637890636920929], ['experience', 'music', 0.16575714945793152], ['psychology', 'fear', 0.17129430174827576], ['minister', 'party', 0.17155185341835022], ['opera', 'performance', 0.1716746687889099], ['drink', 'mouth', 0.1730400025844574], ['video', 'archive', 0.1735074818134308], ['movie', 'critic', 0.17430329322814941], ['population', 'development', 0.17502301931381226], ['victim', 'emergency', 0.17580637335777283], ['psychology', 'health', 0.17619232833385468], ['competition', 'price', 0.17668063938617706], ['street', 'place', 0.17753028869628906], ['boxing', 'round', 0.1775924563407898], ['food', 'preparation', 0.17799314856529236], ['production', 'crew', 0.1793084442615509], ['Mars', 'scientist', 0.17972101271152496], ['hundred', 'percent', 0.18021869659423828], ['situation', 'conclusion', 0.1847420334815979], ['ministry', 'culture', 0.187795490026474], ['start', 'year', 0.190186008810997], ['psychology', 'doctor', 0.19066518545150757], ['consumer', 'confidence', 0.19126541912555695], ['volunteer', 'motto', 0.19127660989761353], ['monk', 'slave', 0.19146226346492767], ['family', 'planning', 0.1914883255958557], ['life', 'lesson', 0.1925291270017624], ['planet', 'star', 0.19317106902599335], ['cup', 'tableware', 0.1948634535074234], ['soap', 'opera', 0.1955799013376236], ['lawyer', 'evidence', 0.1986079216003418], ['impartiality', 'interest', 0.20375370979309082], ['morality', 'importance', 0.2053404152393341], ['equipment', 'maker', 0.20798198878765106], ['king', 'rook', 0.20875594019889832], ['situation', 'isolation', 0.20984451472759247], ['country', 'citizen', 0.20985934138298035], ['tool', 'implement', 0.2123422920703888], ['professor', 'doctor', 0.21336083114147186], ['oil', 'stock', 0.2203981876373291], ['record', 'number', 0.22208692133426666], ['brother', 'monk', 0.22320020198822021], ['fuck', 'sex', 0.22339175641536713], ['life', 'term', 0.2267606556415558], ['forest', 'graveyard', 0.22901120781898499], ['arrangement', 'accommodation', 0.2305612713098526], ['announcement', 'effort', 0.23130609095096588], ['secretary', 'senate', 0.23210789263248444], ['lover', 'quarrel', 0.23226581513881683], ['viewer', 'serial', 0.23336467146873474], ['investigation', 'effort', 0.23487988114356995], ['stroke', 'hospital', 0.23570410907268524], ['coast', 'forest', 0.23609790205955505], ['chance', 'credibility', 0.23921890556812286], ['drug', 'abuse', 0.24085770547389984], ['canyon', 'landscape', 0.24369587004184723], ['luxury', 'car', 0.2445116937160492], ['drink', 'car', 0.24563539028167725], ['consumer', 'energy', 0.2461671233177185], ['announcement', 'warning', 0.24619008600711823], ['Arafat', 'Jackson', 0.24712520837783813], ['start', 'match', 0.24805231392383575], ['treatment', 'recovery', 0.2493065744638443], ['psychology', 'mind', 0.25049889087677], ['change', 'attitude', 0.2514270544052124], ['cup', 'liquid', 0.25183942914009094], ['money', 'laundering', 0.2523637115955353], ['asylum', 'madhouse', 0.2525393068790436], ['dollar', 'profit', 0.25337398052215576], ['dollar', 'buck', 0.2562117576599121], ['fertility', 'egg', 0.2565234899520874], ['weapon', 'secret', 0.2584390640258789], ['psychology', 'discipline', 0.2597163915634155], ['Wednesday', 'news', 0.2601482570171356], ['money', 'deposit', 0.2604113817214966], ['bank', 'money', 0.2613206207752228], ['money', 'bank', 0.2613206207752228], ['baseball', 'season', 0.2622438371181488], ['love', 'sex', 0.26393771171569824], ['movie', 'star', 0.26419907808303833], ['street', 'block', 0.26695922017097473], ['credit', 'card', 0.2681569457054138], ['money', 'property', 0.26824459433555603], ['atmosphere', 'landscape', 0.2697125971317291], ['psychology', 'anxiety', 0.2719925045967102], ['game', 'round', 0.2722221314907074], ['disability', 'death', 0.27521100640296936], ['death', 'inmate', 0.2757277488708496], ['deployment', 'departure', 0.2766171097755432], ['dividend', 'payment', 0.2785915434360504], ['planet', 'space', 0.28036749362945557], ['precedent', 'antecedent', 0.28377142548561096], ['concert', 'virtuoso', 0.28570181131362915], ['cell', 'phone', 0.28629887104034424], ['computer', 'laboratory', 0.2875465750694275], ['Maradona', 'football', 0.28883832693099976], ['game', 'series', 0.29130780696868896], ['century', 'nation', 0.291914701461792], ['network', 'hardware', 0.29377809166908264], ['government', 'crisis', 0.29561758041381836], ['governor', 'office', 0.29663556814193726], ['exhibit', 'memorabilia', 0.3025929927825928], ['hotel', 'reservation', 0.3028254508972168], ['bird', 'crane', 0.30286192893981934], ['monk', 'oracle', 0.3035403788089752], ['lobster', 'food', 0.30510464310646057], ['morality', 'marriage', 0.30624136328697205], ['planet', 'astronomer', 0.30787554383277893], ['news', 'report', 0.3123636543750763], ['psychology', 'depression', 0.3135565221309662], ['money', 'dollar', 0.3135656714439392], ['Arafat', 'peace', 0.3149864077568054], ['seafood', 'sea', 0.3150906562805176], ['lobster', 'wine', 0.3194861114025116], ['planet', 'sun', 0.3206743597984314], ['board', 'recommendation', 0.3211810886859894], ['Arafat', 'terror', 0.32154810428619385], ['decoration', 'valor', 0.3227156698703766], ['book', 'library', 0.324531227350235], ['money', 'wealth', 0.3295103907585144], ['tiger', 'fauna', 0.3297567069530487], ['lad', 'wizard', 0.33023008704185486], ['seven', 'series', 0.3310061991214752], ['day', 'dawn', 0.33108577132225037], ['game', 'victory', 0.3314370810985565], ['telephone', 'communication', 0.3321845233440399], ['museum', 'theater', 0.33256372809410095], ['game', 'defeat', 0.3329892158508301], ['psychology', 'Freud', 0.3330824673175812], ['century', 'year', 0.3348371386528015], ['FBI', 'fingerprint', 0.3378998339176178], ['currency', 'market', 0.3382996618747711], ['skin', 'eye', 0.3397478461265564], ['train', 'car', 0.34025612473487854], ['company', 'stock', 0.3415686786174774], ['profit', 'loss', 0.34199458360671997], ['shower', 'thunderstorm', 0.3426947295665741], ['fighting', 'defeating', 0.34452024102211], ['law', 'lawyer', 0.34465768933296204], ['television', 'film', 0.34557002782821655], ['precedent', 'law', 0.34597018361091614], ['cup', 'drink', 0.35322171449661255], ['cup', 'coffee', 0.3560177981853485], ['lad', 'brother', 0.359592467546463], ['life', 'death', 0.3618777096271515], ['weather', 'forecast', 0.3627207279205322], ['bird', 'cock', 0.3629024028778076], ['book', 'paper', 0.3634625971317291], ['liquid', 'water', 0.3653528094291687], ['physics', 'proton', 0.3664059638977051], ['glass', 'metal', 0.37073972821235657], ['precedent', 'example', 0.3727375268936157], ['food', 'fruit', 0.37409260869026184], ['plane', 'car', 0.3779698312282562], ['cemetery', 'woodland', 0.3819250762462616], ['street', 'avenue', 0.38327035307884216], ['media', 'radio', 0.3899160921573639], ['tennis', 'racket', 0.39200806617736816], ['reason', 'criterion', 0.3923366367816925], ['planet', 'constellation', 0.39312952756881714], ['water', 'seepage', 0.39313435554504395], ['computer', 'keyboard', 0.3963916301727295], ['psychology', 'cognition', 0.39951157569885254], ['nature', 'environment', 0.40284886956214905], ['five', 'month', 0.4040083885192871], ['jaguar', 'cat', 0.4054866135120392], ['deployment', 'withdrawal', 0.40605053305625916], ['computer', 'internet', 0.4068623483181], ['Japanese', 'American', 0.41248849034309387], ['FBI', 'investigation', 0.4171352982521057], ['wood', 'forest', 0.4175162613391876], ['closet', 'clothes', 0.4177303910255432], ['student', 'professor', 0.4206617772579193], ['tiger', 'feline', 0.42671453952789307], ['bishop', 'rabbi', 0.42778125405311584], ['tiger', 'carnivore', 0.42893749475479126], ['environment', 'ecology', 0.42997631430625916], ['bed', 'closet', 0.43194779753685], ['admission', 'ticket', 0.4368831515312195], ['physics', 'chemistry', 0.43719834089279175], ['movie', 'popcorn', 0.44535526633262634], ['day', 'summer', 0.4481317400932312], ['liability', 'insurance', 0.4524446129798889], ['rock', 'jazz', 0.45277100801467896], ['problem', 'challenge', 0.4629538059234619], ['marathon', 'sprint', 0.4636158347129822], ['announcement', 'news', 0.4673331677913666], ['stock', 'market', 0.4680556058883667], ['tiger', 'zoo', 0.4692455232143402], ['smart', 'stupid', 0.47047197818756104], ['movie', 'theater', 0.4741904139518738], ['war', 'troops', 0.47614771127700806], ['psychology', 'science', 0.4808834493160248], ['magician', 'wizard', 0.48634961247444153], ['benchmark', 'index', 0.49516886472702026], ['Mexico', 'Brazil', 0.49549198150634766], ['tiger', 'mammal', 0.49644753336906433], ['game', 'team', 0.4966561794281006], ['planet', 'moon', 0.5024792551994324], ['football', 'tennis', 0.5051179528236389], ['gender', 'equality', 0.5059923529624939], ['drink', 'eat', 0.5070200562477112], ['coast', 'shore', 0.5083667039871216], ['tiger', 'animal', 0.5096533298492432], ['tiger', 'cat', 0.5172962546348572], ['seafood', 'food', 0.5295588374137878], ['OPEC', 'oil', 0.5333777666091919], ['computer', 'software', 0.5444109439849854], ['midday', 'noon', 0.5527406334877014], ['tiger', 'jaguar', 0.5528685450553894], ['psychology', 'psychiatry', 0.5556287169456482], ['cucumber', 'potato', 0.5678562521934509], ['dollar', 'yen', 0.5745355486869812], ['car', 'automobile', 0.5838366746902466], ['baby', 'mother', 0.5839769840240479], ['boy', 'lad', 0.5886159539222717], ['vodka', 'gin', 0.5971748232841492], ['murder', 'manslaughter', 0.6057651042938232], ['calculation', 'computation', 0.6076955795288086], ['furnace', 'stove', 0.6083911061286926], ['television', 'radio', 0.6114970445632935], ['money', 'cash', 0.6151220798492432], ['money', 'cash', 0.6151220798492432], ['gem', 'jewel', 0.6210810542106628], ['doctor', 'nurse', 0.6319523453712463], ['planet', 'galaxy', 0.6338511109352112], ['Jerusalem', 'Palestinian', 0.6342512369155884], ['aluminum', 'metal', 0.6375763416290283], ['bread', 'butter', 0.641726016998291], ['king', 'queen', 0.6510956883430481], ['seafood', 'lobster', 0.6544079780578613], ['Jerusalem', 'Israel', 0.6638748645782471], ['championship', 'tournament', 0.6655317544937134], ['type', 'kind', 0.6666412949562073], ['football', 'basketball', 0.6682467460632324], ['journey', 'voyage', 0.6830853223800659], ['vodka', 'brandy', 0.6881492137908936], ['mile', 'kilometer', 0.7258477807044983], ['football', 'soccer', 0.731354832649231], ['man', 'woman', 0.7664011716842651], ['Harvard', 'Yale', 0.7817696332931519], ['tiger', 'tiger', 1.0000001192092896]]\n"
     ]
    }
   ],
   "source": [
    "def compute_similarity_scores(data):\n",
    "    scores = []\n",
    "\n",
    "    for w1, w2, mean in data:\n",
    "        # empty words\n",
    "        if not w1 or not w2:\n",
    "            continue\n",
    "\n",
    "        # word2vec as tensors for cos_score\n",
    "        w1_vec = torch.from_numpy(wv[w1])\n",
    "        w2_vec = torch.from_numpy(wv[w2])\n",
    "        cos_score = similarity(w1_vec, w2_vec)\n",
    "        \n",
    "        scores.append([w1, w2, cos_score.item()])\n",
    "    return sorted(scores, key=lambda entry: entry[2])\n",
    "    \n",
    "sim_scores = compute_similarity_scores(load_data())\n",
    "print(sim_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the word pairs in the list based on the human judgement scores. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_judgement_scores(data):\n",
    "    return sorted(data, key=lambda entry: entry[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute spearman rank correlation between the two ranked lists obtained in the previous two steps.\n",
    "You do not need to implement the spearman rank correlation calculation from scratch. Feel free to use any Python library. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('love', 'sex', 6.77), ('tiger', 'cat', 7.35), ('tiger', 'tiger', 10.0), ('book', 'paper', 7.46), ('computer', 'keyboard', 7.62), ('computer', 'internet', 7.58), ('plane', 'car', 5.77), ('train', 'car', 6.31), ('telephone', 'communication', 7.5), ('television', 'radio', 6.77), ('media', 'radio', 7.42), ('drug', 'abuse', 6.85), ('bread', 'butter', 6.19), ('cucumber', 'potato', 5.92), ('doctor', 'nurse', 7.0), ('professor', 'doctor', 6.62), ('student', 'professor', 6.81), ('smart', 'student', 4.62), ('smart', 'stupid', 5.81), ('company', 'stock', 7.08), ('stock', 'market', 8.08), ('stock', 'phone', 1.62), ('stock', 'CD', 1.31), ('stock', 'jaguar', 0.92), ('stock', 'egg', 1.81), ('fertility', 'egg', 6.69), ('stock', 'live', 3.73), ('stock', 'life', 0.92), ('book', 'library', 7.46), ('bank', 'money', 8.12), ('wood', 'forest', 7.73), ('money', 'cash', 9.15), ('professor', 'cucumber', 0.31), ('king', 'cabbage', 0.23), ('king', 'queen', 8.58), ('king', 'rook', 5.92), ('bishop', 'rabbi', 6.69), ('Jerusalem', 'Israel', 8.46), ('Jerusalem', 'Palestinian', 7.65), ('holy', 'sex', 1.62), ('fuck', 'sex', 9.44), ('Maradona', 'football', 8.62), ('football', 'soccer', 9.03), ('football', 'basketball', 6.81), ('football', 'tennis', 6.63), ('tennis', 'racket', 7.56), ('Arafat', 'peace', 6.73), ('Arafat', 'terror', 7.65), ('Arafat', 'Jackson', 2.5), ('law', 'lawyer', 8.38), ('movie', 'star', 7.38), ('movie', 'popcorn', 6.19), ('movie', 'critic', 6.73), ('movie', 'theater', 7.92), ('physics', 'proton', 8.12), ('physics', 'chemistry', 7.35), ('space', 'chemistry', 4.88), ('alcohol', 'chemistry', 5.54), ('vodka', 'gin', 8.46), ('vodka', 'brandy', 8.13), ('drink', 'car', 3.04), ('drink', 'ear', 1.31), ('drink', 'mouth', 5.96), ('drink', 'eat', 6.87), ('baby', 'mother', 7.85), ('drink', 'mother', 2.65), ('car', 'automobile', 8.94), ('gem', 'jewel', 8.96), ('journey', 'voyage', 9.29), ('boy', 'lad', 8.83), ('coast', 'shore', 9.1), ('asylum', 'madhouse', 8.87), ('magician', 'wizard', 9.02), ('midday', 'noon', 9.29), ('furnace', 'stove', 8.79), ('food', 'fruit', 7.52), ('bird', 'cock', 7.1), ('bird', 'crane', 7.38), ('tool', 'implement', 6.46), ('brother', 'monk', 6.27), ('crane', 'implement', 2.69), ('lad', 'brother', 4.46), ('journey', 'car', 5.85), ('monk', 'oracle', 5.0), ('cemetery', 'woodland', 2.08), ('food', 'rooster', 4.42), ('coast', 'hill', 4.38), ('forest', 'graveyard', 1.85), ('shore', 'woodland', 3.08), ('monk', 'slave', 0.92), ('coast', 'forest', 3.15), ('lad', 'wizard', 0.92), ('chord', 'smile', 0.54), ('glass', 'magician', 2.08), ('noon', 'string', 0.54), ('rooster', 'voyage', 0.62), ('money', 'dollar', 8.42), ('money', 'cash', 9.08), ('money', 'currency', 9.04), ('money', 'wealth', 8.27), ('money', 'property', 7.57), ('money', 'possession', 7.29), ('money', 'bank', 8.5), ('money', 'deposit', 7.73), ('money', 'withdrawal', 6.88), ('money', 'laundering', 5.65), ('money', 'operation', 3.31), ('tiger', 'jaguar', 8.0), ('tiger', 'feline', 8.0), ('tiger', 'carnivore', 7.08), ('tiger', 'mammal', 6.85), ('tiger', 'animal', 7.0), ('tiger', 'organism', 4.77), ('tiger', 'fauna', 5.62), ('tiger', 'zoo', 5.87), ('psychology', 'psychiatry', 8.08), ('psychology', 'anxiety', 7.0), ('psychology', 'fear', 6.85), ('psychology', 'depression', 7.42), ('psychology', 'clinic', 6.58), ('psychology', 'doctor', 6.42), ('psychology', 'Freud', 8.21), ('psychology', 'mind', 7.69), ('psychology', 'health', 7.23), ('psychology', 'science', 6.71), ('psychology', 'discipline', 5.58), ('psychology', 'cognition', 7.48), ('planet', 'star', 8.45), ('planet', 'constellation', 8.06), ('planet', 'moon', 8.08), ('planet', 'sun', 8.02), ('planet', 'galaxy', 8.11), ('planet', 'space', 7.92), ('planet', 'astronomer', 7.94), ('precedent', 'example', 5.85), ('precedent', 'information', 3.85), ('precedent', 'cognition', 2.81), ('precedent', 'law', 6.65), ('precedent', 'collection', 2.5), ('precedent', 'group', 1.77), ('precedent', 'antecedent', 6.04), ('cup', 'coffee', 6.58), ('cup', 'tableware', 6.85), ('cup', 'article', 2.4), ('cup', 'artifact', 2.92), ('cup', 'object', 3.69), ('cup', 'entity', 2.15), ('cup', 'drink', 7.25), ('cup', 'food', 5.0), ('cup', 'substance', 1.92), ('cup', 'liquid', 5.9), ('jaguar', 'cat', 7.42), ('jaguar', 'car', 7.27), ('energy', 'secretary', 1.81), ('secretary', 'senate', 5.06), ('energy', 'laboratory', 5.09), ('computer', 'laboratory', 6.78), ('weapon', 'secret', 6.06), ('FBI', 'fingerprint', 6.94), ('FBI', 'investigation', 8.31), ('investigation', 'effort', 4.59), ('Mars', 'water', 2.94), ('Mars', 'scientist', 5.63), ('news', 'report', 8.16), ('canyon', 'landscape', 7.53), ('image', 'surface', 4.56), ('discovery', 'space', 6.34), ('water', 'seepage', 6.56), ('sign', 'recess', 2.38), ('Wednesday', 'news', 2.22), ('mile', 'kilometer', 8.66), ('computer', 'news', 4.47), ('territory', 'surface', 5.34), ('atmosphere', 'landscape', 3.69), ('president', 'medal', 3.0), ('war', 'troops', 8.13), ('record', 'number', 6.31), ('skin', 'eye', 6.22), ('Japanese', 'American', 6.5), ('theater', 'history', 3.91), ('volunteer', 'motto', 2.56), ('prejudice', 'recognition', 3.0), ('decoration', 'valor', 5.63), ('century', 'year', 7.59), ('century', 'nation', 3.16), ('delay', 'racism', 1.19), ('delay', 'news', 3.31), ('minister', 'party', 6.63), ('peace', 'plan', 4.75), ('minority', 'peace', 3.69), ('attempt', 'peace', 4.25), ('government', 'crisis', 6.56), ('deployment', 'departure', 4.25), ('deployment', 'withdrawal', 5.88), ('energy', 'crisis', 5.94), ('announcement', 'news', 7.56), ('announcement', 'effort', 2.75), ('stroke', 'hospital', 7.03), ('disability', 'death', 5.47), ('victim', 'emergency', 6.47), ('treatment', 'recovery', 7.91), ('journal', 'association', 4.97), ('doctor', 'personnel', 5.0), ('doctor', 'liability', 5.19), ('liability', 'insurance', 7.03), ('school', 'center', 3.44), ('reason', 'hypertension', 2.31), ('reason', 'criterion', 5.91), ('hundred', 'percent', 7.38), ('Harvard', 'Yale', 8.13), ('hospital', 'infrastructure', 4.63), ('death', 'row', 5.25), ('death', 'inmate', 5.03), ('lawyer', 'evidence', 6.69), ('life', 'death', 7.88), ('life', 'term', 4.5), ('word', 'similarity', 4.75), ('board', 'recommendation', 4.47), ('governor', 'interview', 3.25), ('OPEC', 'country', 5.63), ('peace', 'atmosphere', 3.69), ('peace', 'insurance', 2.94), ('territory', 'kilometer', 5.28), ('travel', 'activity', 5.0), ('competition', 'price', 6.44), ('consumer', 'confidence', 4.13), ('consumer', 'energy', 4.75), ('problem', 'airport', 2.38), ('car', 'flight', 4.94), ('credit', 'card', 8.06), ('credit', 'information', 5.31), ('hotel', 'reservation', 8.03), ('grocery', 'money', 5.94), ('registration', 'arrangement', 6.0), ('arrangement', 'accommodation', 5.41), ('month', 'hotel', 1.81), ('type', 'kind', 8.97), ('arrival', 'hotel', 6.0), ('bed', 'closet', 6.72), ('closet', 'clothes', 8.0), ('situation', 'conclusion', 4.81), ('situation', 'isolation', 3.88), ('impartiality', 'interest', 5.16), ('direction', 'combination', 2.25), ('street', 'place', 6.44), ('street', 'avenue', 8.88), ('street', 'block', 6.88), ('street', 'children', 4.94), ('listing', 'proximity', 2.56), ('listing', 'category', 6.38), ('cell', 'phone', 7.81), ('production', 'hike', 1.75), ('benchmark', 'index', 4.25), ('media', 'trading', 3.88), ('media', 'gain', 2.88), ('dividend', 'payment', 7.63), ('dividend', 'calculation', 6.48), ('calculation', 'computation', 8.44), ('currency', 'market', 7.5), ('OPEC', 'oil', 8.59), ('oil', 'stock', 6.34), ('announcement', 'production', 3.38), ('announcement', 'warning', 6.0), ('profit', 'warning', 3.88), ('profit', 'loss', 7.63), ('dollar', 'yen', 7.78), ('dollar', 'buck', 9.22), ('dollar', 'profit', 7.38), ('dollar', 'loss', 6.09), ('computer', 'software', 8.5), ('network', 'hardware', 8.31), ('phone', 'equipment', 7.13), ('equipment', 'maker', 5.91), ('luxury', 'car', 6.47), ('five', 'month', 3.38), ('report', 'gain', 3.63), ('investor', 'earning', 7.13), ('liquid', 'water', 7.89), ('baseball', 'season', 5.97), ('game', 'victory', 7.03), ('game', 'team', 7.69), ('marathon', 'sprint', 7.47), ('game', 'series', 6.19), ('game', 'defeat', 6.97), ('seven', 'series', 3.56), ('seafood', 'sea', 7.47), ('seafood', 'food', 8.34), ('seafood', 'lobster', 8.7), ('lobster', 'food', 7.81), ('lobster', 'wine', 5.7), ('food', 'preparation', 6.22), ('video', 'archive', 6.34), ('start', 'year', 4.06), ('start', 'match', 4.47), ('game', 'round', 5.97), ('boxing', 'round', 7.61), ('championship', 'tournament', 8.36), ('fighting', 'defeating', 7.41), ('line', 'insurance', 2.69), ('day', 'summer', 3.94), ('summer', 'drought', 7.16), ('summer', 'nature', 5.63), ('day', 'dawn', 7.53), ('nature', 'environment', 8.31), ('environment', 'ecology', 8.81), ('nature', 'man', 6.25), ('man', 'woman', 8.3), ('man', 'governor', 5.25), ('murder', 'manslaughter', 8.53), ('soap', 'opera', 7.94), ('opera', 'performance', 6.88), ('life', 'lesson', 5.94), ('focus', 'life', 4.06), ('production', 'crew', 6.25), ('television', 'film', 7.72), ('lover', 'quarrel', 6.19), ('viewer', 'serial', 2.97), ('possibility', 'girl', 1.94), ('population', 'development', 3.75), ('morality', 'importance', 3.31), ('morality', 'marriage', 3.69), ('Mexico', 'Brazil', 7.44), ('gender', 'equality', 6.41), ('change', 'attitude', 5.44), ('family', 'planning', 6.25), ('opera', 'industry', 2.63), ('sugar', 'approach', 0.88), ('practice', 'institution', 3.19), ('ministry', 'culture', 4.69), ('problem', 'challenge', 6.75), ('size', 'prominence', 5.31), ('country', 'citizen', 7.31), ('planet', 'people', 5.75), ('development', 'issue', 3.97), ('experience', 'music', 3.47), ('music', 'project', 3.63), ('glass', 'metal', 5.56), ('aluminum', 'metal', 7.83), ('chance', 'credibility', 3.88), ('exhibit', 'memorabilia', 5.31), ('concert', 'virtuoso', 6.81), ('rock', 'jazz', 7.59), ('museum', 'theater', 7.19), ('observation', 'architecture', 4.38), ('space', 'world', 6.53), ('preservation', 'world', 6.19), ('admission', 'ticket', 7.69), ('shower', 'thunderstorm', 6.31), ('shower', 'flood', 6.03), ('weather', 'forecast', 8.34), ('disaster', 'area', 6.25), ('governor', 'office', 6.34), ('architecture', 'century', 3.78)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_spearman():\n",
    "    data = load_data()\n",
    "    print(data)\n",
    "\n",
    "    sim_score = np.array(compute_similarity_scores(data))\n",
    "    human_score = np.array(human_judgement_scores(data))\n",
    "\n",
    "    # use third column of dataset (mean/cos_similarity)\n",
    "    preds = torch.from_numpy(sim_score[:, 2].astype(float))\n",
    "    target = torch.from_numpy(human_score[:, 2].astype(float))\n",
    "\n",
    "    spearman = SpearmanCorrCoef()\n",
    "    return spearman(preds, target)\n",
    "    \n",
    "compute_spearman()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding based clasifier\n",
    "We will design a simple sentiment classifier based on the pre-trained word embeddings (google news).\n",
    "\n",
    "Each data point is a movie review and the sentiment could be either positive (1) or negative (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1821"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('sentiment_test_X.p', 'rb') as fs:\n",
    "    test_X = pickle.load(fs)\n",
    "\n",
    "len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If',\n",
       " 'you',\n",
       " 'sometimes',\n",
       " 'like',\n",
       " 'to',\n",
       " 'go',\n",
       " 'to',\n",
       " 'the',\n",
       " 'movies',\n",
       " 'to',\n",
       " 'have',\n",
       " 'fun',\n",
       " ',',\n",
       " 'Wasabi',\n",
       " 'is',\n",
       " 'a',\n",
       " 'good',\n",
       " 'place',\n",
       " 'to',\n",
       " 'start',\n",
       " '.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1821"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('sentiment_test_y.p', 'rb') as fs:\n",
    "    test_y = pickle.load(fs)\n",
    "    \n",
    "len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentiment_train_X.p', 'rb') as fs:\n",
    "    train_X = pickle.load(fs)\n",
    "with open('sentiment_train_y.p', 'rb') as fs:\n",
    "    train_y = pickle.load(fs)\n",
    "with open('sentiment_val_X.p', 'rb') as fs:\n",
    "    val_X = pickle.load(fs)\n",
    "with open('sentiment_val_y.p', 'rb') as fs:\n",
    "    val_y = pickle.load(fs)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a review, compute its embedding by averaging over the embedding of its constituent words. Define a function which given a review as a list of words, generates its embeddings by averaging over the constituent word embeddings. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(review):\n",
    "    res = np.mean([wv[word] for word in review if word in wv], axis=0)\n",
    "    if np.isnan(res).any():\n",
    "        return np.zeros(300)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a feed-forward network class with pytorch. (Hyperparamter choice such as number of layers, hidden size is left to you) (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_1_size, hidden_2_size, output_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_1_size = hidden_1_size\n",
    "        self.hidden_2_size = hidden_2_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.fc_1 = nn.Linear(self.input_size, self.hidden_1_size)\n",
    "        self.fc_2 = nn.Linear(self.hidden_1_size, self.hidden_2_size)\n",
    "        self.fc_3 = nn.Linear(self.hidden_2_size, self.output_size)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.fc_1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc_2.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc_3.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_1 = self.relu(self.fc_1(x))\n",
    "        h_2 = self.relu(self.fc_2(h_1))\n",
    "        y = self.fc_3(h_2)\n",
    "        return self.sigmoid(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dataset class for efficiently enumerating over the dataset. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sent_data(Dataset):\n",
    "    def __init__(self, data_points, class_labels):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.data = data_points\n",
    "        self.labels = class_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        d = torch.FloatTensor(generate_embedding(self.data[index]))\n",
    "        l = torch.FloatTensor([self.labels[index]])\n",
    "        return d,l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a train function to train model. At the end of each epoch compute the validation accuracy and save the model with the best validation accuracy. (12 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function to calculate the accuracy\n",
    "def calc_accuracy(gts, preds):\n",
    "    correct = sum(1 for tc, pred in zip(gts, preds) if tc == pred)\n",
    "    total = len(gts)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "# Adopt your code to incorporate mini-batch training\n",
    "# Use cross-entropy as your loss function\n",
    "def train(model, train_data, val_data, batch_size, epochs=5, learning_rate=0.001):\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    lossfn = nn.BCELoss()\n",
    "    best_accuracy = 0.0\n",
    "    for _ in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        for d, l in train_dataloader:\n",
    "            out = model(d)\n",
    "            loss =  lossfn(out, l)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        model.eval()\n",
    "        val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "        true_classes = []\n",
    "        predicted_classes = []\n",
    "        for d, l in val_dataloader:\n",
    "            out = model(d)\n",
    "            true_classes.extend(l.squeeze(1).tolist())\n",
    "            predictions = torch.where(out > 0.5, 1, 0) # for two classes and out in (0,1) this should be enough for class probabilities? \n",
    "            predicted_classes.extend(predictions.squeeze(1).tolist())\n",
    "            \n",
    "        # Calculate the Accuracy\n",
    "        accuracy = calc_accuracy(true_classes, predicted_classes)\n",
    "\n",
    "        #Check whether current model is better than best model\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model.state_dict()\n",
    "            \n",
    "    # Save the best model\n",
    "    torch.save(best_model, 'best_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the trained model on the test set and report the test accuracy. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "    model.eval()\n",
    "    test_dataloader = DataLoader(test_data)\n",
    "    true_classes = []\n",
    "    predicted_classes = []\n",
    "    for d,l in test_dataloader:\n",
    "        out = model(d)\n",
    "        true_classes.extend(l)\n",
    "        predictions = torch.where(out > 0.5, 1, 0)\n",
    "        predicted_classes.extend(predictions.squeeze(1).tolist())\n",
    "        \n",
    "    # Calculate the Accuracy\n",
    "    accuracy = calc_accuracy(true_classes, predicted_classes)\n",
    "\n",
    "    print(\"The accuracy of the best model on the test set is: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|                       | 36/50 [00:44<00:17,  1.26s/it]"
     ]
    }
   ],
   "source": [
    "# REMEMBER: Maybe implement GPU training for faster execution\n",
    "train_data = sent_data(train_X, train_y)\n",
    "val_data = sent_data(val_X, val_y)\n",
    "test_data = sent_data(test_X, test_y)\n",
    "model = Classifier(300, 100, 50, 1)\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "train(model, train_data, val_data, batch_size, epochs)\n",
    "best_model_state = torch.load('best_model.pth')\n",
    "model.load_state_dict(best_model_state)\n",
    "evaluate(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing random words\n",
    "print(model.forward(torch.Tensor(wv[\"good\"])))\n",
    "print(model.forward(torch.Tensor(wv[\"awful\"])))\n",
    "print(model.forward(torch.Tensor(wv[\"eventually\"])))\n",
    "print(model.forward(torch.Tensor(wv[\"boring\"])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
